# gans

## Data Management with DVC

This project uses [DVC](https://dvc.org/) to manage the data. To use it, you need to have DVC installed and configured with a remote storage (e.g., S3, GCS, or a shared network drive).

### Initial Setup

1.  **Initialize DVC:**
    ```bash
    dvc init
    ```

2.  **Configure remote storage:**
    Follow the instructions on the DVC documentation to configure your remote storage. For example, for S3:
    ```bash
    dvc remote add -d myremote s3://my-bucket/gans-data
    ```

### Data Pipeline

1.  **Download the data:**
    Download the BreakHis dataset from Kaggle and the CAMELYON16/17 datasets. Place them in a temporary directory.

2.  **Extract patches:**
    Use the `extract_patches.py` script to extract patches from the whole-slide images.
    ```bash
    python extract_patches.py --wsi_dir /path/to/wsis --output_dir data/raw
    ```

3.  **Add data to DVC:**
    ```bash
    dvc add data/raw
    ```

4.  **Push data to remote storage:**
    ```bash
    dvc push
    ```

### Getting the data

To get the data, simply run:
```bash
dvc pull
```
This will download the data from the remote storage and place it in the `data/raw` directory.

## Training

To train the models, you can use the `train.py` script. The script is configured to use Hydra for configuration management and MLflow for experiment tracking.

### Single run

To train a single model, you can run the following command:
```bash
python src/train.py model=dcgan
```
This will train the DCGAN model with the default configuration specified in `configs/dcgan.yaml`. You can override the configuration parameters from the command line, for example:
```bash
python src/train.py model=dcgan batch_size=32
```

### Multi-run

To train multiple models in parallel, you can use the multi-run functionality of Hydra:
```bash
python src/train.py -m model=dcgan,wgan_gp,stylegan2_ada
```
This will launch three separate runs, one for each model. The logs for each run will be saved in a separate directory under `logs`.

### Sweeps

To run a hyperparameter sweep, you can use the `sweep.yaml` configuration file:
```bash
python src/train.py -m --config-name sweep
```
This will launch a sweep with the search space defined in `configs/sweep.yaml`.

### MLflow Tracking

By default, MLflow logs are saved to the `logs` directory. To use a different tracking URI, you can set the `MLFLOW_TRACKING_URI` environment variable:
```bash
export MLFLOW_TRACKING_URI=http://localhost:5000
python src/train.py model=dcgan
```

## Evaluation

The training script uses MLflow to log the experiment results. To view the results, you can launch the MLflow UI:
```bash
mlflow ui
```
This will launch a web server at http://localhost:5000 where you can view the experiment logs, compare the performance of the different models, and view the generated images.

### Histo-QC Overlay

For a qualitative evaluation of the generated patches, you can use the Histo-QC overlay. This involves overlaying the generated patches with quality control masks to check if the generated artifacts are consistent with the practice of a pathologist. An example notebook can be found at [notebooks/histo_qc_overlay.ipynb](notebooks/histo_qc_overlay.ipynb).

## Graph-based Module

This project includes a graph-based module that can be integrated into the GAN models to improve the generation of realistic histopathological patches. The module is composed of two main components: a graph builder and a GNN block.

### Graph Builder

The `src/graph_builder.py` script is responsible for extracting a graph from a histopathology image. It does this by first detecting the centroids of the nuclei in the image and then building a graph from these centroids using either Delaunay triangulation or Voronoi tessellation.

### GNN Block

The `src/gnn_block.py` script defines a generic GNN block that can be integrated into the GAN models. The block is based on the GraphSAGE architecture and can be used to process the graphs generated by the graph builder.

### Integration

To integrate the graph-based module into a GAN model, you need to:

1.  **Extract the graph from the image:** Use the `detect_nuclei_centroids` and `build_graph` functions from `src/graph_builder.py` to extract the graph from the input image.
2.  **Add a GNN block to the generator:** Add a `GraphBlock` to the generator architecture to process the graph and generate a graph-based feature map. This feature map can then be combined with the image-based feature map to generate the final image.

    ```
    Image Feature Map ----------------> |
                                        | ----> Concatenate ----> Final Image
    Graph Feature Map ----------------> |
    ```
3.  **Add a graph-based discriminator:** Add a parallel path to the discriminator to evaluate the consistency of the generated graph with the generated image. This can be done by adding a GNN block to the discriminator to process the graph and a classifier to predict whether the graph is real or fake.

### Graph-based Metrics

To evaluate the quality of the generated graphs, you can use graph-based metrics such as the Normalized Discounted Cumulative Gain (nDCG). The nDCG metric can be used to compare the ranking of the nodes in the generated graph with the ranking of the nodes in the real graph.
